# 导入所需的库
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from tqdm.auto import tqdm  # 用于显示训练进度条
import pandas as pd

# 设置随机种子以确保结果可重复
torch.manual_seed(42)
np.random.seed(42)

# 真实的物理模型参数
true_params = {
    'a': 0.7970752950355046,
    'b': -0.00022326007646824328,
    'c': 0.003576877157164809,
    'd': -2.21633997e+03,
    'e': 4.75019240e+03,
    'f': -2.58116991e+03,
    'g': 2.18583682e-01,
    'h': -3.61933871e-01,
    'i': -4.37280696e+03,
    'j': 2.55455265e+02,
    'k': -2.23658579e-04,
    'l': 2.64887323e-02,
    'm': 5.47807475e-02
}

df = pd.read_excel("data-2inputs(3).xlsx", sheet_name=0)

# 生成数据集
x1 = torch.tensor(df.iloc[:, 0].values, dtype=torch.float32).unsqueeze(-1) # 生成 x1 数据，并增加一个维度
x2 = torch.tensor(df.iloc[:, 3].values, dtype=torch.float32).unsqueeze(-1)  # 生成 x2 数据，并增加一个维度
x3 = torch.tensor(df.iloc[:, 1].values, dtype=torch.float32).unsqueeze(-1) # 生成 x3 数据，并增加一个维度
x4 = torch.tensor(df.iloc[:, 2].values, dtype=torch.float32).unsqueeze(-1)  # 生成 x4 数据，并增加一个维度
y = torch.tensor(df.iloc[:, 4].values, dtype=torch.float32).reshape(-1, 1)

# 定义训练集和验证集
x1_train, x2_train, x3_train, x4_train, y_train = x1[:125], x2[:125], x3[:125], x4[:125], y[:125]  # 前220个数据点用于训练
x1_val, x2_val, x3_val, x4_val, y_val = x1[:], x2[:], x3[:], x4[:], y[:]  # 所有数据用于验证

# 定义基于物理模型的神经网络类
class PDM(nn.Module):
    def __init__(self, hidden_sizes, input_count, activation_fn=nn.LeakyReLU, physics_func=None, params=None):
        super(PDM, self).__init__()
        self.input_count = input_count
        self.network = nn.Sequential()

        # 指定物理参数值
        if params:
            self.a = nn.Parameter(torch.tensor(0.7970752950355046))
            self.b = nn.Parameter(torch.tensor(-0.00022326007646824328))
            self.c = nn.Parameter(torch.tensor(0.003576877157164809))
            self.d = nn.Parameter(torch.tensor(-2.21633997e+03))
            self.e = nn.Parameter(torch.tensor(4.75019240e+03))
            self.f = nn.Parameter(torch.tensor(-2.58116991e+03))
            self.g = nn.Parameter(torch.tensor(2.18583682e-01))
            self.h = nn.Parameter(torch.tensor(-3.61933871e-01))
            self.i = nn.Parameter(torch.tensor(-4.37280696e+03))
            self.j = nn.Parameter(torch.tensor(2.55455265e+02))
            self.k = nn.Parameter(torch.tensor(-2.23658579e-04))
            self.l = nn.Parameter(torch.tensor(2.64887323e-02))
            self.m = nn.Parameter(torch.tensor(5.47807475e-02))
        # 构建神经网络
        input_size = input_count  # 根据输入数量设置输入层大小
        for i, hidden_size in enumerate(hidden_sizes):
            self.network.add_module(f"Linear_{i}", nn.Linear(input_size, hidden_size))
            if activation_fn is not None:
                self.network.add_module(f"Activation_{i}", activation_fn())
            input_size = hidden_size
        self.network.add_module("Output", nn.Linear(input_size, 1))

        self.physics_trained = False
        self.physics_func = physics_func if physics_func is not None else self.default_physics_func

    def forward(self, x1, x2, x3=None, x4=None):
        inputs = [x1, x2]
        if self.input_count > 2:
            inputs.extend([x3, x4])
        x = torch.cat(inputs[:self.input_count], dim=1)
        neural_output = self.network(x)
        return neural_output

    def physics(self, x1, x2, x3=None, x4=None):
        # 使用训练后的物理参数进行预测
        if self.physics_func:
            return self.physics_func({
                'a': self.a, 'b': self.b, 'c': self.c,
                'd': self.d, 'e': self.e, 'f': self.f,
                'g': self.g, 'h': self.h, 'i': self.i,
                'j': self.j, 'k': self.k, 'l': self.l, 'm': self.m}, x1, x2, x3, x4)
        else:
            return self.default_physics_func(x1, x2, x3, x4)

    @staticmethod
    def default_physics_func(x1, x2, x3, x4):
        return torch.zeros_like(x1, x2, x3, x4)

    def mark_physics_trained(self):
        self.physics_trained = True

# 定义物理模型函数
def physics_model_1(params, x1, x2, x3=None, x4=None):
    return params['a'] + params['b'] * torch.sqrt(x1) + params['c'] * torch.sqrt(x2)

def physics_model_2(params, x1, x2, x3, x4):
    return ((params['d'] * (x3 / x1) + params['e'] * torch.sqrt(x3 / x1) + params['f'] +
             params['g'] * torch.sqrt(x1) + params['h'] * torch.sqrt(x2)) /
            (params['i'] + params['j'] * torch.sqrt(x4)) +
             params['k'] * x2 + params['l'] * torch.sqrt(x2) + params['m'])

# 定义隐藏层的大小
hidden_sizes_model_1 = [6, 6, 4, 6, 6, 6, 6, 4, 6, 6]
hidden_sizes_model_2 = [15, 17, 18, 17, 18, 17, 17, 18, 17, 17, 17, 17, 15]  #0.976 13ceng
# hidden_sizes_model_2 = [15, 17, 17, 18, 17, 17, 18, 17, 17, 16, 17, 17, 16, 15]

# 创建模型时指定物理参数的值
model_1_params = {
    'a': 0.7970752950355046,
    'b': -0.00022326007646824328,
    'c': 0.003576877157164809,
}
model_1 = PDM(hidden_sizes_model_1, input_count=2, activation_fn=nn.LeakyReLU, physics_func=physics_model_1, params=model_1_params)

model_2_params = {
    'd': -2.21633997e+03,
    'e': 4.75019240e+03,
    'f': -2.58116991e+03,
    'g': 2.18583682e-01,
    'h': -3.61933871e-01,
    'i': -4.37280696e+03,
    'j': 2.55455265e+02,
    'k': -2.23658579e-04,
    'l': 2.64887323e-02,
    'm': 5.47807475e-02
}
model_2 = PDM(hidden_sizes_model_2, input_count=4, activation_fn=nn.LeakyReLU, physics_func=physics_model_2, params=model_2_params)
# 使用不同的物理模型函数和网络结构创建模型
models = [model_1, model_2]

def combined_loss(model, predictions, targets, x1, x2, x3, x4, lambda_physics=0.4999):
    # 数据损失（均方误差）
    data_loss = nn.MSELoss()(predictions, targets)
    # 物理损失
    physics_pred = model.physics(x1, x2, x3, x4)
    physics_loss = nn.MSELoss()(physics_pred, targets)  # 应将物理预测与目标进行比较
    # 综合损失
    total_loss = (1 - lambda_physics) * data_loss + lambda_physics * physics_loss
    return total_loss


def physics_loss_only(model, x1, x2,  x3, x4, targets):
    # 仅计算物理损失
    physics_pred = model.physics(x1, x2,  x3, x4)
    return nn.MSELoss()(physics_pred, targets)


# 使用较小的学习率进行优化
optimizers = [torch.optim.Adam(model.parameters(), lr=0.001) for model in models]

# 定义神经网络参数训练的周期数
num_epochs = 20000
# 定义物理参数训练的周期数
num_epochs_physics = 30000

# 定义每个模型的优化器，分别设置不同的学习率
optimizers_physics = [
    torch.optim.Adam(
        [
            {'params': [model.a, model.b, model.c], 'lr': 0.005},  # 对abc设置学习率为0.005
            {'params': [model.d, model.e, model.f, model.g, model.h, model.i, model.j, model.k, model.l, model.m], 'lr': 0.0005}  # 对defghijklm设置学习率为0.0001
        ],
        lr=0.001
    ) for model in models
]

# 创建只针对非物理参数的优化器
optimizers_non_physics = [
    torch.optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)
    for model in models
]

# 物理模型参数训练循环
for epoch in tqdm(range(num_epochs_physics), desc="Physics Training"):
    for model, optimizer in zip(models, optimizers_physics):
        optimizer.zero_grad()
        # 使用物理模型函数进行预测。这里假设物理模型函数已经被正确赋予模型
        physics_pred = model.physics(x1_train, x2_train, x3_train, x4_train)
        loss = nn.MSELoss()(physics_pred, y_train)
        loss.backward()
        optimizer.step()

        # 每200次迭代打印一次物理损失
        if epoch % 200 == 0:
            print(f"Epoch {epoch}: Physics Loss = {loss.item()}")

# 物理模型参数训练完成后，标记物理模型参数已训练
for model in models:
    model.mark_physics_trained()

# 冻结物理参数
for model in models:
    for param_name, param in model.named_parameters():
        if param_name in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']:  # 假设true_params包含所有物理参数名称
            param.requires_grad = False

# 训练完成后，提取每个模型的物理参数
trained_params_models = []
for model in models:
    trained_params = {
        'a': model.a.item(),
        'b': model.b.item(),
        'c': model.c.item(),
        'd': model.d.item(),
        'e': model.e.item(),
        'f': model.f.item(),
        'g': model.g.item(),
        'h': model.h.item(),
        'i': model.i.item(),
        'j': model.j.item(),
        'k': model.k.item(),
        'l': model.l.item(),
        'm': model.m.item()
    }
    trained_params_models.append(trained_params)

# 展示每个模型训练后的物理参数与真实参数的对比
for i, params in enumerate(trained_params_models):
    print(f"Model {i + 1} trained physics parameters vs true parameters:")
    for param in params:
        print(f"{param}: Trained={params[param]:.4f}, True={true_params[param]}")
    print("")  # 添加空行以分隔每个模型的输出

# 使用训练后的参数来生成预测曲线
def generate_prediction(trained_params_model_1, trained_params_model_2, x1, x2, x3, x4):
    # 解析出模型1的参数
    a, b, c = (trained_params_model_1[k] for k in ['a', 'b', 'c'])
    # 解析出模型2的参数
    d, e, f, g, h, i, j, k, l, m = (trained_params_model_2[k] for k in ['d', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm'])

    # 基于您之前的描述，这里将根据提供的物理模型逻辑进行调整
    # 假设prediction_model_1仍然按照原来的逻辑生成
    prediction_model_1 = a + b * torch.sqrt(x1) + c * torch.sqrt(x2)

    # 根据物理模型2的描述调整prediction_model_2的生成逻辑
    # 这里将使用所有提供的参数和变量，确保符合您之前定义的物理模型函数
    prediction_model_2 = ((d * (x3 / x1) + e * torch.sqrt(x3 / x1) + f + g * torch.sqrt(x1) + h * torch.sqrt(x2)) /
                          (i + j * torch.sqrt(x4)) + k * x2 + l * torch.sqrt(x2) + m)

    return prediction_model_1, prediction_model_2


x1_indices = np.arange(len(x1_val))
x2_indices = np.arange(len(x2_val))
x3_indices = np.arange(len(x3_val))
x4_indices = np.arange(len(x4_val))

# 创建可视化
plt.figure(figsize=(12, 6))

# # 绘制纯物理模型1预测数据与实际数据的对比
# with torch.no_grad():
#     # 使用训练后的物理参数进行预测
#     physics_pred_model_1 = generate_prediction(trained_params_models[0], trained_params_models[0], x1_val, x2_val, x3_val, x4_val)[0]
#
# plt.scatter(x1_indices, y_val.numpy(), color='blue', alpha=0.5, label='Measurement Data')
# plt.plot(x1_indices, physics_pred_model_1.numpy(), label='Trained Physics Model 1 Prediction', color='green', linewidth=2, linestyle='--')

# 绘制纯物理模型2预测数据与实际数据的对比
with torch.no_grad():
    # 使用训练后的物理参数进行预测
    physics_pred_model_2 = generate_prediction(trained_params_models[1], trained_params_models[1], x1_val, x2_val, x3_val, x4_val)[1]

plt.scatter(x1_indices, y_val.numpy(), color='blue', alpha=0.5)  # 重新绘制测量数据散点图
plt.plot(x1_indices, physics_pred_model_2.numpy(), label='Trained Physics Model 2 Prediction', color=(148/255, 0, 211/255), linewidth=2, linestyle='--')

plt.title('Physics Model Comparison: Measurement vs. Predictions')
plt.xlabel('Data Points')
plt.ylabel('Eta')
plt.legend()

plt.tight_layout()
plt.show()

# 网络其余部分的训练循环
for model, optimizer in zip(models, optimizers_non_physics):
    for epoch in tqdm(range(num_epochs), desc="Training Non-Physics Parameters", leave=False):
        optimizer.zero_grad()
        predictions = model(x1_train, x2_train, x3_train, x4_train)
        loss = combined_loss(model, predictions, y_train, x1_train, x2_train, x3_train, x4_train, lambda_physics=0.4999
                             )
        loss.backward()
        optimizer.step()

        # 每隔500次打印一次神经网络损失
        if epoch % 500 == 0:
            print(f"Epoch {epoch}: Neural Network Loss = {loss.item()}")

# 准备数据和模型预测结果用于可视化
x_val_np = x1_val.numpy().flatten()  # 转换为numpy数组，方便绘图
y_val_np = y_val.numpy().flatten()

# 获取每个PDM模型的预测结果
model_predictions = [model(x1_val, x2_val, x3_val, x4_val).detach().numpy().flatten() for model in models]

# 获取每个物理模型的预测结果
physics_predictions = [model.physics(x1_val, x2_val, x3_val, x4_val).detach().numpy().flatten() for model in models]

# 计算每个模型（包括物理模型）的MSE损失，用于计算权重
mse_losses = [nn.MSELoss()(torch.tensor(pred), y_val).item() for pred in model_predictions + physics_predictions]

# 计算每个模型的损失
for i, mse in enumerate(mse_losses):
    print(f"Model {i+1} MSE Loss: {mse}")

# 计算权重（倒数法，损失越小权重越大）
# weights = [1.0 / mse for mse in mse_losses]
weights = [0.286848021768137, 0.302862306133289, 0.191905984295179, 0.218383687803395]
weight_sum = sum(weights)
normalized_weights = [w / weight_sum for w in weights]

# 打印权重
for i, weight in enumerate(normalized_weights):
    print(f"Model {i+1} Weight: {weight}")
# 集成预测
ensemble_predictions = torch.zeros_like(y_val)
for pred, weight in zip(model_predictions + physics_predictions, normalized_weights):
    # 确保pred为正确的形状
    pred_tensor = torch.tensor(pred).unsqueeze(-1)  # 增加一个维度以匹配ensemble_predictions
    ensemble_predictions += pred_tensor * weight

# # 绘制子图1
# plt.figure(figsize=(18, 6))
#
# plt.subplot(1, 3, 1)
# plt.scatter(x1_indices, y_val_np, color='blue', alpha=0.5, label='Measurement Data')
# plt.plot(x1_indices, model_predictions[0], label='PDM 1 Prediction', color='green', linewidth=1, linestyle='--')
# plt.plot(x1_indices, model_predictions[1], label='PDM 2 Prediction', color=(148/255, 0, 211/255), linewidth=1, linestyle='--')
# plt.plot(x1_indices, ensemble_predictions.numpy().flatten(), label='Ensemble Learning Prediction', color='red', linewidth=2, linestyle='-')
# plt.title('PDM vs. Ensemble Learning Prediction', fontsize=18)  # 设置图标题字体大小
# plt.xlabel('Data Points', fontsize=16)  # 设置横坐标标签字体大小
# plt.ylabel('Eta', fontsize=16)  # 设置纵坐标标签字体大小
# plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
# plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小
# plt.legend(fontsize=14)  # 设置图例字体大小
#
# # 绘制子图2
# plt.subplot(1, 3, 2)
# plt.scatter(x1_indices, y_val_np, color='blue', alpha=0.5, label='Measurement Data')
# plt.plot(x1_indices, physics_predictions[0], label='Physics Model 1 Prediction', color='green', linewidth=1, linestyle='--')
# plt.plot(x1_indices, physics_predictions[1], label='Physics Model 2 Prediction', color=(148/255, 0, 211/255), linewidth=1, linestyle='--')
# plt.title('Physics Model Prediction', fontsize=18)  # 设置图标题字体大小
# plt.xlabel('Data Points', fontsize=16)  # 设置横坐标标签字体大小
# plt.ylabel('Eta', fontsize=16)  # 设置纵坐标标签字体大小
# plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
# plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小
# plt.legend(fontsize=14)  # 设置图例字体大小
#
# # 绘制子图3
# plt.subplot(1, 3, 3)
# model_labels = ['PDM 1', 'PDM 2', 'Physics Model 1', 'Physics Model 2']
# plt.bar(model_labels, normalized_weights[:4], color=['green', 'red', 'blue', 'orange'])
# plt.title('Contribution of Models to Ensemble Learning', fontsize=18)  # 设置图标题字体大小
# plt.xlabel('Model', fontsize=16)  # 设置横坐标标签字体大小
# plt.ylabel('Contribution Weight', fontsize=16)  # 设置纵坐标标签字体大小
# plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
# plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小
#
# plt.tight_layout()
# plt.show()

# 绘制子图1
plt.figure(figsize=(12, 6))

# plt.subplot(1, 2, 1)
plt.scatter(x1_indices, y_val_np, color='blue', alpha=0.5, label='Measurement Data')
# plt.plot(x1_indices, model_predictions[0], label='PDM 1 Prediction', color='green', linewidth=1, linestyle='--')
plt.plot(x1_indices, model_predictions[1], label='PDM 2 Prediction', color=(148/255, 0, 211/255), linewidth=1, linestyle='--')
# plt.plot(x1_indices, ensemble_predictions.numpy().flatten(), label='Ensemble Learning Prediction', color='red', linewidth=2, linestyle='-')
plt.title('PDM vs. Ensemble Learning Prediction', fontsize=18)  # 设置图标题字体大小
plt.xlabel('Data Points', fontsize=16)  # 设置横坐标标签字体大小
plt.ylabel('Eta', fontsize=16)  # 设置纵坐标标签字体大小
plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小
plt.legend(fontsize=14)  # 设置图例字体大小

# # 绘制子图3
# plt.subplot(1, 2, 2)
# model_labels = ['PDM 1', 'PDM 2', 'Physics Model 1', 'Physics Model 2']
# plt.bar(model_labels, normalized_weights[:4], color=['green', 'red', 'blue', 'orange'])
# # plt.title('Contribution of Models to Ensemble Learning', fontsize=18)  # 设置图标题字体大小
# plt.xlabel('Model', fontsize=16)  # 设置横坐标标签字体大小
# plt.ylabel('Contribution Weight', fontsize=16)  # 设置纵坐标标签字体大小
# plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
# plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小

plt.tight_layout()
plt.show()

# 计算模型与实际数据的偏差
# physics_model_1_deviation = np.abs(physics_pred_model_1.numpy().flatten() - y_val_np)
physics_model_2_deviation = np.abs(physics_pred_model_2.numpy().flatten() - y_val_np)
ensemble_deviation = np.abs(ensemble_predictions.numpy().flatten() - y_val_np)

# 创建物理模型与实际数据的对比偏差图
plt.figure(figsize=(12, 6))

# plt.plot(x1_indices, physics_model_1_deviation, label='Physics Model 1 Deviation', color='green', linewidth=1, linestyle='--')
plt.plot(x1_indices, physics_model_2_deviation, label='Physics Model 2 Deviation', color=(148/255, 0, 211/255), linewidth=1, linestyle='--')
# plt.scatter(x1_indices, ensemble_deviation, label='Ensemble Learning Deviation', color='red', linewidth=2, linestyle='-')
plt.title('Deviation of Models from Actual Data', fontsize=18)  # 设置图标题字体大小
plt.xlabel('Data Points', fontsize=16)  # 设置横坐标标签字体大小
plt.ylabel('Relative Deviation', fontsize=16)  # 设置纵坐标标签字体大小
plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小
plt.legend(fontsize=14)  # 设置图例字体大小

plt.tight_layout()
plt.show()

# 计算PDM模型与实际数据的偏差
# pdm_model_1_deviation = np.abs(model_predictions[0] - y_val_np)
pdm_model_2_deviation = np.abs(model_predictions[1] - y_val_np)

# 创建PDM模型与实际数据的对比偏差图
plt.figure(figsize=(12, 6))

# plt.plot(x1_indices, pdm_model_1_deviation, label='PDM Model 1 Deviation', color='green', linewidth=1, linestyle='--')
plt.plot(x1_indices, pdm_model_2_deviation, label='PDM Model 2 Deviation', color=(148/255, 0, 211/255), linewidth=1, linestyle='--')
# plt.scatter(x1_indices, ensemble_deviation, label='Ensemble Learning Deviation', color='red', linewidth=2, linestyle='-')
plt.title('Deviation of PDM Models from Actual Data', fontsize=18)  # 设置图标题字体大小
plt.xlabel('Data Points', fontsize=16)  # 设置横坐标标签字体大小
plt.ylabel('Relative Deviation', fontsize=16)  # 设置纵坐标标签字体大小
plt.xticks(fontsize=14)  # 设置横坐标刻度字体大小
plt.yticks(fontsize=14)  # 设置纵坐标刻度字体大小
plt.legend(fontsize=14)  # 设置图例字体大小

plt.tight_layout()
plt.show()

# 计算偏差百分比
# physics_model_1_deviation_percentage = physics_model_1_deviation / y_val_np * 100
physics_model_2_deviation_percentage = physics_model_2_deviation / y_val_np * 100
# pdm_model_1_deviation_percentage = pdm_model_1_deviation / y_val_np * 100
pdm_model_2_deviation_percentage = pdm_model_2_deviation / y_val_np * 100
# ensemble_deviation_percentage = ensemble_deviation / y_val_np * 100

# 创建DataFrame
data = {
    # 'Physics Model 1 Deviation (%)': physics_model_1_deviation_percentage,
    'Physics Model 2 Deviation (%)': physics_model_2_deviation_percentage,
    # 'PDM Model 1 Deviation (%)': pdm_model_1_deviation_percentage,
    'PDM Model 2 Deviation (%)': pdm_model_2_deviation_percentage,
    # 'Ensemble Learning Deviation (%)': ensemble_deviation_percentage,
    'Actual Data': y_val_np
}
df = pd.DataFrame(data)

# 输出到Excel表格
df.to_excel('绝对误差-deviation_percentage.xlsx', index=False)

import pandas as pd

# 计算相对误差偏差百分比
# physics_model_1_relative_deviation_percentage = abs(physics_pred_model_1.numpy().flatten() - y_val_np) / y_val_np * 100
physics_model_2_relative_deviation_percentage = abs(physics_pred_model_2.numpy().flatten() - y_val_np) / y_val_np * 100
# pdm_model_1_relative_deviation_percentage = abs(model_predictions[0] - y_val_np) / y_val_np * 100
pdm_model_2_relative_deviation_percentage = abs(model_predictions[1] - y_val_np) / y_val_np * 100
# ensemble_relative_deviation_percentage = abs(ensemble_predictions.numpy().flatten() - y_val_np) / y_val_np * 100

# 创建DataFrame
data_relative = {
    # 'Physics Model 1 Relative Deviation (%)': physics_model_1_relative_deviation_percentage,
    'Physics Model 2 Relative Deviation (%)': physics_model_2_relative_deviation_percentage,
    # 'PDM Model 1 Relative Deviation (%)': pdm_model_1_relative_deviation_percentage,
    'PDM Model 2 Relative Deviation (%)': pdm_model_2_relative_deviation_percentage,
    # 'Ensemble Learning Relative Deviation (%)': ensemble_relative_deviation_percentage,
    'Actual Data': y_val_np
}
df_relative = pd.DataFrame(data_relative)

# 输出到Excel表格
df_relative.to_excel('相对误差-relative_deviation_percentage.xlsx', index=False)

# 将结果保存到数据框中
results_df = pd.DataFrame({
    # 'Physics Model 1 Prediction': physics_predictions[0],
    'Physics Model 2 Prediction': physics_predictions[1],
    # 'PDM Model 1 Prediction': model_predictions[0],
    'PDM Model 2 Prediction': model_predictions[1],
    'Actual Efficiency': y_val.numpy().flatten()
})

# 将数据框导出为 Excel 文件
results_df.to_excel("model_predictions.xlsx", index=False)

print("Results have been saved to 'model_predictions.xlsx'.")

import pandas as pd

# 模型权重数据
model_labels = ['PDM 1', 'PDM 2', 'Physics Model 1', 'Physics Model 2']
normalized_weights = normalized_weights[:4]  # 取前4个模型的权重

# 创建一个DataFrame来存储模型名称和权重
df_weights = pd.DataFrame({
    'Model': model_labels,
    'Weight': normalized_weights
})

# 将DataFrame写入Excel文件
output_file_path = 'model_weights.xlsx'  # 你可以指定你的文件路径
df_weights.to_excel(output_file_path, index=False)

print(f"模型权重已成功导出到 {output_file_path}")

# 使用验证集进行预测
with torch.no_grad():  # 不计算梯度
    pdm_model_2_neural_pred = model_2(x1_val, x2_val, x3_val, x4_val)

# 将PDM模型2的预测结果转换为NumPy数组
pdm_model_2_neural_pred_np = pdm_model_2_neural_pred.numpy().flatten()

# 可视化PDM模型2的神经网络预测结果
plt.figure(figsize=(12, 6))
plt.scatter(x1_indices, y_val_np, color='blue', alpha=0.5, label='Measurement Data')
# 绘制PDM模型2的神经网络预测结果
plt.plot(x1_indices, pdm_model_2_neural_pred_np, label='PDM Model 2 Neural Network Prediction', color='purple', linewidth=2)

# 绘制物理模型的预测结果（如果之前没有绘制）
# plt.plot(x1_indices, physics_pred_model_1.numpy(), label='Physics Model 1 Prediction', color='green')
# plt.plot(x1_indices, physics_pred_model_2.numpy(), label='Physics Model 2 Prediction', color='orange')

plt.title('PDM Model 2 Neural Network Prediction vs. Actual Data')
plt.xlabel('Data Points')
plt.ylabel('Eta')
plt.legend()
plt.show()

# 创建DataFrame存储PDM模型2的神经网络预测结果
pdm_model_2_neural_pred_df = pd.DataFrame({
    'PDM Model 2 Neural Network Prediction': pdm_model_2_neural_pred_np,
    'Actual Data': y_val_np.flatten()
})

# 导出到Excel文件
pdm_model_2_neural_pred_df.to_excel('PDM_Model_2_Neural_Network_Prediction.xlsx', index=False)

print("PDM Model 2 neural network predictions have been saved to 'PDM_Model_2_Neural_Network_Prediction.xlsx'.")

from sklearn.metrics import r2_score
import matplotlib.pyplot as plt

# 假设pdm_model_2_neural_pred_np是PDM模型2的预测结果数组，y_val_np是实际值数组
pdm_model_2_predictions = pdm_model_2_neural_pred_np
actual_values = y_val_np

# 计算R²值
r_squared = r2_score(actual_values, pdm_model_2_predictions)

# 绘制PDM模型2的预测值与实际数据的散点图
plt.figure(figsize=(8, 6))
plt.scatter(pdm_model_2_predictions, actual_values, color='blue', alpha=0.5, label='Data Points')

# 添加一条线表示完美预测（参考线）
min_val = min(min(pdm_model_2_predictions), min(actual_values))
max_val = max(max(pdm_model_2_predictions), max(actual_values))
plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)  # 黑色虚线

# 添加R²值文本
plt.text(max_val - max_val * 0.01, max_val * 0.95, f'R² = {r_squared:.3f}', fontsize=14, ha='right')

plt.title('PDM Model 2 Prediction vs. Actual Data with R² Value')
plt.xlabel('PDM Model 2 Predictions')
plt.ylabel('Actual Data')
plt.legend()

# 显示图表
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np

# 假设以下变量已经被计算并包含所需的预测结果和实际数据：
# physics_predictions[1] - 物理模型2的预测结果，假设这是一个numpy数组
# model_predictions[1] - PDM模型2的预测结果，假设这是一个numpy数组
# pdm_model_2_neural_pred_np - PDM模型2中纯神经网络的预测结果，假设这是一个numpy数组
# y_val - 验证集的实际数据，假设这是一个numpy数组

# 如果它们是numpy数组，直接扁平化
physics_predictions_2 = physics_predictions[1].flatten()

# 计算相对误差
physics_model_2_relative_deviation = (
    np.abs(physics_predictions_2 - y_val.numpy().flatten()) / y_val.numpy().flatten() * 100
)

# 确保PDM模型2和神经网络预测结果也是扁平化的numpy数组
pdm_model_2_predictions = model_predictions[1].flatten()
pdm_model_2_neural_predictions = pdm_model_2_neural_pred_np.flatten()
actual_values = y_val.numpy().flatten()

# 计算PDM模型2和神经网络的相对误差
pdm_model_2_relative_deviation = (
    np.abs(pdm_model_2_predictions - actual_values) / actual_values * 100
)
pdm_model_2_neural_relative_deviation = (
    np.abs(pdm_model_2_neural_predictions - actual_values) / actual_values * 100
)

# 创建包含所有结果的DataFrame
final_results_df = pd.DataFrame({
    'Physics Model 2 Prediction': physics_predictions_2,
    'PDM Model 2 Prediction': pdm_model_2_predictions,
    'PDM Model 2 Neural Network Prediction': pdm_model_2_neural_predictions,
    'Actual Data': actual_values,
    'Physics Model 2 Relative Deviation (%)': physics_model_2_relative_deviation,
    'PDM Model 2 Relative Deviation (%)': pdm_model_2_relative_deviation,
    'PDM Model 2 Neural Network Relative Deviation (%)': pdm_model_2_neural_relative_deviation
})

# 保存到Excel文件
output_excel_file_path = 'final_results.xlsx'
final_results_df.to_excel(output_excel_file_path, index=False)
print(f"最终结果已成功导出到 {output_excel_file_path}")
